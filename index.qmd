---
title: "Random Forest in the Health Industry - Spring 2025"
subtitle: "An analysis of the random forest algorithm and its applications in the health industry"
author: "Maddie Sortino and Jisa (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

## Introduction

Machine learning has significantly advanced predictive analytics,
particularly in the medical industry and clinical decision-making. Among
many other algorithms, random forest (RF) has become an effective tool
due to the fact that it can handle high-dimensional data, is not prone
to overfitting, and has high accuracy in predicting events (Breiman,
2001; Rigatti, 2017). RF is an ensemble learning method that is made up
of various decision trees that are generated through bagging and random
feature selection. These trees’ efforts in bootstrap aggregation can
result in finer classification and different regression predictions than
the classical statistical models (Biau & Scornet, 2016; Boulesteix et
al., 2012). This flexibility gives the experts in the biomedical
industry the ability to address various tasks like cancer survival
analysis, disease progression prediction, and resource management
optimization in healthcare.

RF, among other uses, survival analysis has been one of the most notable
applications in demonstrating patient outcomes in colon cancer research.
This study involves the analysis of SEER data and presents the
comparison of RF and the Cox proportional hazards model in terms of
utilization and handling of missing data and complicated interactions
(Breiman, 2001). RF has also been a popular tool in other clinical
applications, such as good predictions for ICU patients who are at high
risk of sepsis (Zhang et al., 2018). Another life-saving decision
support application of RF is that it can not only forecast diabetes
development, but it can also provide personalized guidance for
healthcare professionals to prevent the disease and improve the health
of patients (Smith et al., 2021).

The algorithm’s capability of handling imbalanced datasets, its
applicability in medical diagnostics has been further enhanced. As a
direct example, to investigate the prediction of vulnerabilities to
diseases from the subjects of the imbalanced datasets, the most accurate
method became an ensured desired result via repeated random subsampling,
outperforming the support vector machine, boosting, and bagging methods
(Khalilia et al., 2011). Furthermore, RF is utilized in healthcare
resource planning, such as projecting the demand for the necessary drugs
in the public health facilities to, therefore, ensure supply chain
efficiency and prevent shortages (Mbonyinshuti et al., 2022).

RF is a powerful algorithm, but it also has its own disadvantages.
Hyperparameter tuning is an incredibly important feature that one can
use to maximize their predictive accuracy with the number of trees (L),
the sample size for each tree, and the number of variables considered at
each split (mtry), among other factors, all significantly contributing
to the models' performance (Oshiro et al., 2012; Probst et al., 2019).
While it is true that the RF technique performs excellently using the
default hyperparameter settings, the method of tuning can have an
optimal effect on the model's operation beyond reliability or speed
(Boulesteix et al., 2012). The problem, however, of model
interpretability is the one that stands out above all, and it is very
much needed to be resolved in the field of medicine where making
decisions is necessary (Smith et al., 2021). Also, researchers have
suggested other methods of data analysis that could improve model
reliability and at the same time reduce bias during variable selection,
for example, conditional inference forests (CIF) (Dai et al., 2018).

Ever since RF was first used in the medical industry to achieve clinical
diagnoses, it has been regarded as the best tool in the medical
prediction model space. Here we are comparing the performance of Random
Forest with traditional statistical techniques and also discussing
whether any advancements made in hyperparameter optimization in recent
times would come in handy in this regard. This study is an analysis of
RF based on a combination of information extracted from different
sources. Therefore, it is the most comprehensive understanding of RF’s
high potential and where it needs more refinement in healthcare
analytics.

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
