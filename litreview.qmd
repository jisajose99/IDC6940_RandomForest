## Week 2 Research Progress

[@rigatti2017random]
The goal of this paper is to explore and describe
the random forest technique. It provides an overview of the decision
tree process and how random forests are created using decision trees.
The explanations in the article are very useful for understanding the
process. It goes into detail about CART models, how a decision tree is
formed using randomization techniques such as bootstrapping and bagging,
and then randomization at each node. The article briefly explains being
able to tune the model with number of splits and number of trees, which
affect the computational intensity. The article then focuses on using a
random forest to analyze survival data. Colon cancer data is used to
create models using both random forest and Cox, and results are found to
be comparable. The main drawback the author writes of the random forest
as compared to Cox, is that it doesn't give insights into partial
effects of the predictors, making it much more difficult to understand
how the predictors may individually or collectively be influencing the
prediction.

[@oshiro2012many]
The purpose of this article is to research whether there is an optimal number of trees within a random forest. The goal is to determine if there's a threshold in which increasing the number of trees provides no significant performance gain as compared to the increase of computational cost. The article states that in general, the user sets the number of trees on a trial and error basis. They review the results from an analysis of increasing the number of trees, between 2 and 4096, doubling the number of trees at every iteration for 29 data sets. The number of attributes within each random forest is also analyzed with the growth of trees. Results were analyzed using ROC curve (AUC) and the percentage of attributes used. In general, as the number of trees increased, so did the AUC. However, there was no significant difference between the given number of trees and double that number. We needed to do at least 4x the number to see a significant improvement. There was no significant difference between 128 trees until 4096 trees. The article suggests that based on their experiments, a range between 64 and 128 trees in a forest tends to be an optimal balance between AUC, processing time, and memory usage. 

[@probst2019hyperparameters]
The purpose of this article is to examine the hyperparameters and tuning strategies for random forests. It reviews the various hyperparameters that must be set (i.e. number of trees, number of observations drawn randomly for each tree, replacement, number of variables for each split, etc). There are defaults for all of these hyperparameters if the user does not specify, however, the purpose of tuning these hyperparameters is to achieve optimal results for the specific data set being utilized. The article breaks down the hyperparameter analysis into sections – influence on performance and influence on variable importance; with subsection for each hyperparameter. They state that an optimal compromise between low correlation and reasonable strength of the trees has to be found, which can be controlled by the parameters mtry, sample size, and node size. The article did a great job diving into the different hyperparameters, explaining their purpose, why typical default values are what they are, and how choosing different values can affect the models. The article discusses how random forests are generally known to provide good results using the default settings, and tuning of hyperparameters is overall much less necessary/beneficial than other algorithms. It reviews various R packages and functions that can be used for hyperparameter tuning and how each function works – such as tuneRF which calculates the out-of-bag error with the default mtry value, and then tries smaller or larger values until there is no more improvement and returns the model with the best value. The authors also delve into the details of a tuning package they created, tuneRanger, and compare it to existing R packages. Overall, it exceeded in nearly every category – MMCE, AUC, Brier score, Logarithmic loss, and Training runtime. The variable mtry has shown to have the most potential when tuning a random forest model. 

[@dai2018using]
The purpose of this paper is to analyze the diagnosis of breast cancer using the random forest algorithm. The article begins with giving a basic background of the algorithm and how it functions. It then breaks down into sections further detailing the different steps and aspects of the random forest, such as bagging sampling and decision tree construction. “That is to say, in each round of random sampling of bagging, about 36.8% of the data in the training set is not collected by the sample set.” This is referred to as the Out Of Bag data, which is then used for testing the model. The data set used in the paper is the University of California, Irvine Breast Cancer Wisconsin (Diagnostic) Dataset, which has 569 medical records of multidimensional data. The article describes the different fields that are in the data set and does some basic proportional and correlation analysis. The author was able to achieve approximately 95% accuracy on the model and ROC OOB of 99.3%. This shows that the random forest can be a great choice in diagnosis prediction by producing classification results. 
